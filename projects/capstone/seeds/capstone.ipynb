{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available classes\n",
    "seed_types = os.listdir('train')\n",
    "seed_dict = {}\n",
    "[seed_dict.update({k:v}) for v,k in enumerate(seed_types)]\n",
    "seed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def get_data(train_path):\n",
    "    data = {}\n",
    "    for i in os.listdir(train_path):\n",
    "        data[i] =  data[i] = [train_path + i + \"/\" + j for j in os.listdir(train_path + i)]\n",
    "\n",
    "        print i + \" contains \" + str(len(data[i])) + \" images\"\n",
    "    return data\n",
    "\n",
    "# Improve the quality of the images\n",
    "def transform_image(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    lab_planes = cv2.split(lab)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n",
    "\n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "    lab_planes[1] = clahe.apply(lab_planes[1])\n",
    "    lab_planes[2] = clahe.apply(lab_planes[2])\n",
    "\n",
    "    lab = cv2.merge(lab_planes)\n",
    "\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    #img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    #x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = np.array(img)\n",
    "    img = transform_image(img)\n",
    "    \n",
    "    np_image = np.asarray(img)\n",
    "    return np.expand_dims(np_image, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "# Call back which reports the f1 score\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average = 'micro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average = 'micro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average = 'micro')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print '— val_f1: %f — val_precision: %f — val_recall %f' %(_val_f1, _val_precision, _val_recall)\n",
    "        return\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "# Plot the history that is stored by keras\n",
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = get_data('train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "for key in data.keys():\n",
    "    for i in data[key]:\n",
    "        train_x.append(i)\n",
    "        train_y.append(seed_dict[key]) \n",
    "len(train_x), len(train_y)\n",
    "\n",
    "# one hot encode the y values\n",
    "train_y = keras.utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,seed in enumerate(seed_types):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    img = plt.imread(data[seed][100])\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    img = plt.imread(data[seed][i])\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed='Common wheat'\n",
    "img_path = data[seed][2]\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check transformed image\n",
    "img2 = np.array(img)\n",
    "plt.imshow(transform_image(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into tenors\n",
    "train_tensors = paths_to_tensor(train_x).astype('float32')/255\n",
    "#test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('test.n',train_tensors)\n",
    "#train_tensors = np.load('test.n.npy')\n",
    "#p.dump(train_tensors,open('train_tensors.p','wb'))\n",
    "#train_tensors = p.load(open( \"train_tensors.p\", \"rb\" ))\n",
    "type(train_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model for testing\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16,kernel_size=2,input_shape=(224,224,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32,(2,2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64,(2,2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(12,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the model into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_tensors, train_y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = image.ImageDataGenerator(\n",
    "    featurewise_center = True,\n",
    "    featurewise_std_normalization = True,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train), steps_per_epoch=len(X_train)/32,\n",
    "          epochs=epochs, validation_data=(X_test, y_test), callbacks=[checkpointer, metrics], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the ResNet model\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "r50_model = ResNet50(input_tensor = input_tensor, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = r50_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='sigmoid')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "# this is the model we will train\n",
    "r50_model = Model(inputs=r50_model.input, outputs=predictions)\n",
    "\n",
    "for layer in r50_model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in r50_model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "### TODO: Compile the model.\n",
    "r50_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "#for i, layer in enumerate(r50_model.layers):\n",
    " #  print(i, layer.name)\n",
    "\n",
    "#r50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model.\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.resnet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history = r50_model.fit_generator(datagen.flow(X_train, y_train), steps_per_epoch=len(X_train)/32,\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=20, callbacks=[checkpointer, metrics], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model.\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.resnet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history = r50_model.fit(X_train, y_train,\n",
    "          validation_data=(X_test, y_test), batch_size=32,\n",
    "          epochs=20, callbacks=[checkpointer, metrics], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_seed_dict = {}\n",
    "[reverse_seed_dict.update({v:k}) for k,v in seed_dict.items()]\n",
    "\n",
    "def predict_img(path):\n",
    "    img = plt.imread(path)\n",
    "    plt.imshow(img)\n",
    "    idx = np.where(1==model.predict(path_to_tensor(path))[0])[0][0]\n",
    "    print(reverse_seed_dict[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_img(data[seed][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below code is to create submission for kaggle, not documented for capstone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = ['test/'+i for i in os.listdir('test/')]\n",
    "test_tensors = paths_to_tensor(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = model.predict(test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([os.listdir('test/'), [np.argmax(i) for i in l]]).transpose()\n",
    "df.columns =['file', 'species']\n",
    "df['species'] = df['species'].map(reverse_seed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('something.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_seed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
